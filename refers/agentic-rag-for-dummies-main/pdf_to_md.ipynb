{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsdHJxiU4nYbIH9ZYGR75o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiovanniPasq/agentic-rag-for-dummies/blob/main/pdf_to_md.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PDF to Markdown Conversion for RAG Systems\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Converting PDF documents to Markdown is often the **most critical step** in building an effective RAG (Retrieval-Augmented Generation) system. Markdown strikes an optimal balance: it preserves the structural hierarchy of the original document (headers, lists, tables, code, formulas) while remaining lightweight and directly consumable by LLMs without additional preprocessing.\n",
        "\n",
        "**Why Markdown over plain text or JSON?**\n",
        "\n",
        "While plain text extraction is fast and JSON provides structured data, **Markdown is superior for RAG systems** because it:\n",
        "\n",
        "- **Preserves document structure**: Headers, subheaders, lists, and formatting hierarchy remain intact, helping LLMs understand the logical flow and relationships between sections\n",
        "- **Maintains semantic meaning**: Bold, italic, code blocks, and other formatting cues provide context that aids comprehension\n",
        "- **Handles complex elements naturally**: Tables, code blocks, mathematical formulas, and blockquotes are represented in a standardized, readable format\n",
        "- **Human and machine readable**: Unlike JSON's rigid key-value structure or plain text's lack of hierarchy, Markdown balances readability for both humans and LLMs\n",
        "- **Optimal for chunking**: Clear structural boundaries (headers, paragraphs) make intelligent document chunking straightforward for retrieval\n",
        "\n",
        "Plain text loses all formatting and structure, making it difficult for retrieval systems to distinguish between titles, body text, and metadata. JSON can capture structure but often requires custom schemas and is verbose for text-heavy documents. Markdown naturally bridges this gap.\n",
        "\n",
        "**Why is this conversion so important?**\n",
        "\n",
        "The quality of your RAG system is fundamentally constrained by the quality of your extracted data. Poorly extracted or \"dirty\" data‚Äîtext with broken formatting, missing tables, garbled formulas, or lost context‚Äîleads directly to inaccurate retrieval and hallucinated responses. Before implementing any extraction pipeline, you must ask yourself:\n",
        "\n",
        "- **What type of content do my PDFs contain?** Plain text only? Images? Tables? Mathematical formulas?\n",
        "- **How complex is the layout?** Single-column? Multi-column? Mixed layouts with sidebars?\n",
        "- **Are there visual elements?** Diagrams, charts, photographs that carry semantic meaning?\n",
        "- **Are the documents scanned?** Scanned PDFs require OCR capabilities regardless of layout complexity.\n",
        "\n",
        "Based on these questions, you can categorize your PDFs into three complexity tiers:\n",
        "\n",
        "---\n",
        "\n",
        "## PDF Complexity Classification\n",
        "\n",
        "**üü¢ Simple PDFs (Category 1)**\n",
        "- Text-only documents with standard layouts\n",
        "- Digital PDFs with selectable text\n",
        "- Examples: Reports, articles, plain books, documentation\n",
        "- **Note:** If scanned, move to Category 2 (OCR required)\n",
        "\n",
        "**üü° Medium Complexity PDFs (Category 2)**\n",
        "- Documents with tables and basic formatting\n",
        "- Scanned documents (even if simple layout)\n",
        "- PDFs with occasional images\n",
        "- Multi-column layouts\n",
        "- Examples: Academic papers, business reports, scanned books\n",
        "\n",
        "**üî¥ Complex PDFs (Category 3)**\n",
        "- Image-heavy documents where visuals carry critical information\n",
        "- Complex charts, diagrams, and infographics\n",
        "- Mixed content types with spatial relationships\n",
        "- Examples: Scientific papers with diagrams, medical reports, technical manuals, presentations\n",
        "\n",
        "---\n",
        "\n",
        "## Extraction Methods Overview\n",
        "\n",
        "| Complexity Level | Recommended Tools | Key Capability |\n",
        "|-----------------|-------------------|----------------|\n",
        "| **Simple (Digital Text)** | PyMuPDF4LLM, PyMuPDF, PDFPlumber | Fast text extraction |\n",
        "| **Medium (Tables/Scanned)** | Docling, Marker, PaddleOCR | OCR + Table structure |\n",
        "| **Complex (Image-Heavy)** | Vision-Language Models (VLMs) | Visual understanding |\n",
        "\n",
        "---\n",
        "\n",
        "## Category 1: Simple PDFs - Fast Text Extraction\n",
        "\n",
        "**Use these tools when:** Your PDFs are digital (not scanned), contain primarily text with simple formatting, and have no critical visual elements.\n",
        "\n",
        "**Available Tools:**\n",
        "- **PyMuPDF4LLM** - https://github.com/pymupdf/PyMuPDF4LLM (Optimized for LLM consumption)\n",
        "- **PDFPlumber** - https://github.com/jsvine/pdfplumber (Fine-grained control with table detection)\n",
        "- **MarkItDown** - https://github.com/microsoft/markitdown (Zero-configuration, multiple formats)\n",
        "\n",
        "### Example Implementation: PyMuPDF4LLM"
      ],
      "metadata": {
        "id": "6t4MQxjrXG8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf4llm"
      ],
      "metadata": {
        "id": "Yj1_znjKYyh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymupdf4llm\n",
        "import pathlib\n",
        "\n",
        "def convert_simple_pdfs_pymupdf4llm(pdf_folder: str, output_folder: str):\n",
        "    \"\"\"\n",
        "    Convert simple text-based PDFs to Markdown using PyMuPDF4LLM.\n",
        "\n",
        "    Args:\n",
        "        pdf_folder: Path to folder containing PDF files\n",
        "        output_folder: Path to output folder for Markdown files\n",
        "    \"\"\"\n",
        "    pdf_path = pathlib.Path(pdf_folder)\n",
        "    output_path = pathlib.Path(output_folder)\n",
        "    output_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for pdf_file in pdf_path.glob(\"*.pdf\"):\n",
        "        try:\n",
        "            # Extract text as Markdown\n",
        "            md_text = pymupdf4llm.to_markdown(str(pdf_file))\n",
        "\n",
        "            # Save to file\n",
        "            output_file = output_path / f\"{pdf_file.stem}.md\"\n",
        "            output_file.write_text(md_text, encoding='utf-8')\n",
        "\n",
        "            print(f\"‚úì Converted: {pdf_file.name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚úó Error processing {pdf_file.name}: {e}\")\n",
        "\n",
        "    print(f\"\\nConversion complete! Output in '{output_folder}'\")\n",
        "\n",
        "# Example usage\n",
        "convert_simple_pdfs_pymupdf4llm(\"./simple_pdfs\", \"./md_output\")"
      ],
      "metadata": {
        "id": "1V-drtZ7Y5Nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Category 2: Medium Complexity PDFs - OCR + Structure Recognition\n",
        "\n",
        "**Use these tools when:** You have scanned documents, tables that need structure preservation, or multi-column layouts.\n",
        "\n",
        "**Available Tools:**\n",
        "- **Docling** - https://github.com/DS4SD/docling (OCR + table structure + optional VLM integration)\n",
        "- **Marker** - https://github.com/VikParuchuri/marker (Fast conversion with excellent layout preservation)\n",
        "- **PaddleOCR** - https://github.com/PaddlePaddle/PaddleOCR (Multilingual OCR, 80+ languages, optional VLM integration)\n",
        "\n",
        "### Example Implementation: Docling\n",
        "**Reference:** [Docling Documentation](https://docling-project.github.io/docling/)\n"
      ],
      "metadata": {
        "id": "OB7gmgvkZb7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docling"
      ],
      "metadata": {
        "id": "0sxaE-HTZaqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
        "from docling.datamodel.base_models import InputFormat\n",
        "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
        "\n",
        "def convert_medium_pdfs_docling(pdf_folder: str, output_folder: str):\n",
        "    \"\"\"\n",
        "    Convert medium-complexity PDFs using Docling with OCR and table extraction.\n",
        "\n",
        "    Args:\n",
        "        pdf_folder: Path to folder containing PDF files\n",
        "        output_folder: Path to output folder for Markdown files\n",
        "    \"\"\"\n",
        "    pipeline_options = PdfPipelineOptions()\n",
        "    pipeline_options.do_table_structure = True  # Extract table structures\n",
        "    pipeline_options.do_ocr = True  # Enable OCR for scanned content\n",
        "    pipeline_options.images_scale = 2.0  # Higher quality image extraction\n",
        "    pipeline_options.generate_picture_images = True\n",
        "\n",
        "    converter = DocumentConverter(\n",
        "        format_options={\n",
        "            InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
        "        }\n",
        "    )\n",
        "\n",
        "    output_path = Path(output_folder)\n",
        "    output_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    pdf_files = list(Path(pdf_folder).glob(\"*.pdf\"))\n",
        "\n",
        "    for pdf_file in pdf_files:\n",
        "        try:\n",
        "            result = converter.convert(str(pdf_file))\n",
        "            markdown_content = result.document.export_to_markdown()\n",
        "\n",
        "            output_file = output_path / f\"{pdf_file.stem}.md\"\n",
        "            output_file.write_text(markdown_content, encoding='utf-8')\n",
        "\n",
        "            print(f\"‚úì Converted: {pdf_file.name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚úó Error processing {pdf_file.name}: {e}\")\n",
        "\n",
        "    print(f\"\\nConversion complete! Output in '{output_folder}'\")\n",
        "\n",
        "# Example usage\n",
        "convert_medium_pdfs_docling(\"./medium_pdfs\", \"./md_output\")"
      ],
      "metadata": {
        "id": "jOZMJn9_ZfXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Category 3: Complex PDFs - Vision-Language Models (VLMs)\n",
        "\n",
        "**Use VLMs when:** Your PDFs contain critical visual information‚Äîcharts, diagrams, complex layouts, or image-heavy content where visual elements must be accurately described and contextualized.\n",
        "\n",
        "### The VLM Approach\n",
        "\n",
        "The VLM approach works by converting each PDF page into a high-resolution image and sending it to a vision-language model with instructions to extract and convert the content into structured Markdown. This method leverages the model's visual understanding capabilities to:\n",
        "\n",
        "1. **Recognize text** in any layout or orientation\n",
        "2. **Interpret visual elements** like charts, diagrams, and images\n",
        "3. **Understand spatial relationships** between document elements\n",
        "4. **Preserve document structure** through proper Markdown formatting\n",
        "5. **Generate descriptions** for non-text elements\n",
        "\n",
        "**How it works:**\n",
        "- Each PDF page is rendered as a high-resolution image (typically 300 DPI)\n",
        "- The image is sent to the VLM along with a detailed system prompt\n",
        "- The model analyzes the visual content and outputs structured Markdown\n",
        "- Pages are processed sequentially and combined into a single document\n",
        "\n",
        "This approach is particularly powerful because the model \"sees\" the document as a human would, understanding context, layout, and visual meaning that traditional parsers might miss.\n",
        "\n",
        "### Why Choose VLMs?\n",
        "\n",
        "- **Best for:** Scientific papers, infographics, medical reports, technical diagrams\n",
        "- **Pros:** Highest accuracy, excellent visual element description, preserves spatial relationships, handles any layout complexity\n",
        "- **Cons:** Slower processing, requires API costs (or significant compute for local models)\n",
        "\n",
        "### Cloud vs Local Deployment\n",
        "\n",
        "**Cloud VLMs (Recommended for most users):**\n",
        "- Google Gemini 2.0 Flash / 1.5 Pro (cost-effective: ~$0.075-0.30 per 1M tokens)\n",
        "- OpenAI GPT-4o / GPT-4o-mini\n",
        "- Anthropic Claude 3.5 Sonnet / Haiku\n",
        "\n",
        "**Local VLMs (For privacy/offline requirements):**\n",
        "- Performance depends heavily on model size and hardware\n",
        "- Larger models = better accuracy (e.g., Qwen2-VL 72B > Qwen2-VL 7B)\n",
        "- Examples: Qwen2-VL, LLaVA, BakLLaVA, CogVLM\n",
        "- Requires significant GPU memory (24GB+ for 7B models, 80GB+ for 70B+ models)\n",
        "- Can be run via Ollama, vLLM, or Hugging Face Transformers\n",
        "\n",
        "**Cost Note:** Google Gemini is particularly cost-effective for PDF conversion tasks, offering excellent quality-to-price ratio with Gemini 2.0 Flash being the most economical option for production workloads.\n",
        "\n",
        "**Alternative Tool:**\n",
        "- **Dolphin** - https://github.com/bytedance/Dolphin (Specialized VLM for PDF to Markdown conversion)\n",
        "\n",
        "### Custom System Prompt for VLM Conversion"
      ],
      "metadata": {
        "id": "nNh5vXvYZ87r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Customize this system prompt based on your PDF type (e.g., academic, technical, legal).\n",
        "# This template works for 90% of documents‚Äîtweak rules as needed for your use case.\n",
        "SYSTEM_PROMPT = \"\"\"You are an expert document parser specializing in converting PDF pages to markdown format.\n",
        "\n",
        "**Your task:**\n",
        "Extract ALL content from the provided page image and return it as clean, well-structured markdown.\n",
        "\n",
        "**Text Extraction Rules:**\n",
        "1. Preserve the EXACT text as written (including typos, formatting, special characters)\n",
        "2. Maintain the logical reading order (top-to-bottom, left-to-right)\n",
        "3. Preserve hierarchical structure using appropriate markdown headers (#, ##, ###)\n",
        "4. Keep paragraph breaks and line spacing as they appear\n",
        "5. Use markdown lists (-, *, 1.) for bullet points and numbered lists\n",
        "6. Preserve text emphasis: **bold**, *italic*, `code`\n",
        "7. For multi-column layouts, extract left column first, then right column\n",
        "\n",
        "**Tables:**\n",
        "- Convert all tables to markdown table format\n",
        "- Preserve column alignment and structure\n",
        "- Use | for columns and - for headers\n",
        "\n",
        "**Mathematical Formulas:**\n",
        "- Convert to LaTeX format: inline `$formula$`, display `$$formula$$`\n",
        "- If LaTeX conversion is uncertain, describe the formula clearly\n",
        "\n",
        "**Images, Diagrams, Charts:**\n",
        "- Insert markdown image placeholder: `![Description](image)`\n",
        "- Provide a detailed, informative description including:\n",
        "  * Type of visual (photo, diagram, chart, graph, illustration)\n",
        "  * Main subject or purpose\n",
        "  * Key elements, labels, or data points\n",
        "  * Colors, patterns, or notable visual features\n",
        "  * Context or relationship to surrounding text\n",
        "- For charts/graphs: mention axes, data trends, and key values\n",
        "- For diagrams: describe components and their relationships\n",
        "\n",
        "**Special Elements:**\n",
        "- Footnotes: Use markdown footnote syntax `[^1]`\n",
        "- Citations: Preserve as written\n",
        "- Code blocks: Use triple backticks with language specification\n",
        "- Quotes: Use `>` for blockquotes\n",
        "- Links: Preserve as `[text](url)` if visible\n",
        "\n",
        "**Quality Guidelines:**\n",
        "- DO NOT add explanations, comments, or meta-information\n",
        "- DO NOT skip or summarize content\n",
        "- DO NOT invent or hallucinate text not present in the image\n",
        "- DO NOT include \"Here is the markdown...\" or similar preambles\n",
        "- Output ONLY the markdown content, nothing else\n",
        "\n",
        "**Output Format:**\n",
        "Return raw markdown with no wrapper, no code blocks, no explanations.\n",
        "Start immediately with the page content.\n",
        "\"\"\".strip()"
      ],
      "metadata": {
        "id": "WO8cd60LaJuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation with Google Gemini\n",
        "\n",
        "This implementation demonstrates the page-by-page conversion approach.\n",
        "\n",
        "**Reference:** [Gemini API ‚Äì Image Understanding](https://ai.google.dev/gemini-api/docs/image-understanding)\n",
        "\n"
      ],
      "metadata": {
        "id": "RX6TewI4aPki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF google-genai"
      ],
      "metadata": {
        "id": "A0vFK3QTaQ7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import fitz  # PyMuPDF\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "def convert_complex_pdfs_vlm(pdf_path: str, api_key: str, model: str = \"gemini-2.0-flash\"):\n",
        "    \"\"\"\n",
        "    Convert a single PDF using VLM (Vision-Language Model).\n",
        "\n",
        "    Args:\n",
        "        pdf_path: Path to PDF file\n",
        "        api_key: Google Gemini API key\n",
        "        model: Model name (gemini-2.0-flash, gemini-1.5-pro, etc.)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping page numbers to markdown content\n",
        "    \"\"\"\n",
        "    client = genai.Client(api_key=api_key)\n",
        "    pdf_document = fitz.open(pdf_path)\n",
        "    markdown_pages = {}\n",
        "\n",
        "    for page_num in range(pdf_document.page_count):\n",
        "        try:\n",
        "            page = pdf_document[page_num]\n",
        "\n",
        "            # Convert page to high-resolution image (300 DPI)\n",
        "            pix = page.get_pixmap(matrix=fitz.Matrix(300/72, 300/72))\n",
        "            img_data = pix.tobytes(\"png\")\n",
        "\n",
        "            # Prepare image for VLM\n",
        "            image = types.Part.from_bytes(data=img_data, mime_type=\"image/png\")\n",
        "\n",
        "            # Generate markdown from image\n",
        "            response = client.models.generate_content(\n",
        "                config=types.GenerateContentConfig(\n",
        "                    system_instruction=SYSTEM_PROMPT,\n",
        "                    temperature=0.1  # Low temperature for consistent output\n",
        "                ),\n",
        "                model=model,\n",
        "                contents=[\n",
        "                    \"Convert this PDF page to clean, structured markdown. \"\n",
        "                    \"Extract all text, describe images, and preserve the layout.\",\n",
        "                    image\n",
        "                ],\n",
        "            )\n",
        "\n",
        "            markdown_pages[page_num + 1] = response.text\n",
        "            print(f\"‚úì Processed page {page_num + 1}/{pdf_document.page_count}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚úó Error on page {page_num + 1}: {e}\")\n",
        "            markdown_pages[page_num + 1] = f\"<!-- Error processing page: {e} -->\"\n",
        "\n",
        "    pdf_document.close()\n",
        "    return markdown_pages\n",
        "\n",
        "\n",
        "def batch_convert_complex_pdfs(pdf_folder: str, output_folder: str, api_key: str):\n",
        "    \"\"\"\n",
        "    Batch convert all PDFs in a folder using VLM.\n",
        "\n",
        "    Args:\n",
        "        pdf_folder: Path to folder containing PDF files\n",
        "        output_folder: Path to output folder for Markdown files\n",
        "        api_key: Google Gemini API key\n",
        "    \"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for filename in os.listdir(pdf_folder):\n",
        "        if filename.lower().endswith('.pdf'):\n",
        "            print(f\"\\nüìÑ Processing: {filename}\")\n",
        "            pdf_path = os.path.join(pdf_folder, filename)\n",
        "            pdf_name = os.path.splitext(filename)[0]\n",
        "\n",
        "            # Convert PDF\n",
        "            markdown_pages = convert_complex_pdfs_vlm(pdf_path, api_key)\n",
        "\n",
        "            # Combine pages into single markdown file\n",
        "            combined_markdown = \"\\n\\n---\\n\\n\".join([\n",
        "                f\"# Page {page_num}\\n\\n{content}\"\n",
        "                for page_num, content in markdown_pages.items()\n",
        "            ])\n",
        "\n",
        "            # Save to file\n",
        "            output_path = os.path.join(output_folder, f\"{pdf_name}.md\")\n",
        "            with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(combined_markdown)\n",
        "\n",
        "            print(f\"‚úì Saved: {output_path}\")\n",
        "\n",
        "    print(f\"\\nüéâ Batch conversion complete! Output in '{output_folder}'\")\n",
        "\n",
        "# Example usage\n",
        "batch_convert_complex_pdfs(\"./complex_pdfs\", \"./md_output\", \"your-gemini-api-key\")"
      ],
      "metadata": {
        "id": "mCZuqCwwaUpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Comparison Matrix\n",
        "\n",
        "| Feature | PyMuPDF4LLM | PDFPlumber | MarkItDown | Docling | Marker | PaddleOCR | VLM (Gemini) |\n",
        "|---------|------------|------------|------------|---------|---------|-----------|--------------|\n",
        "| **Speed** | ‚ö°‚ö°‚ö° | ‚ö°‚ö°‚ö° | ‚ö°‚ö°‚ö° | ‚ö°‚ö° | ‚ö°‚ö° | ‚ö°‚ö° | ‚ö° |\n",
        "| **Accuracy** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |\n",
        "| **Table Extraction** | ‚ùå | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚ö†Ô∏è | ‚úÖ |\n",
        "| **Image Description** | ‚ùå | ‚ùå | ‚ùå | ‚ö†Ô∏è | ‚ö†Ô∏è | ‚ùå | ‚úÖ |\n",
        "| **OCR Support** | ‚ùå | ‚ùå | ‚ö†Ô∏è | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |\n",
        "| **Complex Layouts** | ‚ùå | ‚ùå | ‚ùå | ‚ö†Ô∏è | ‚úÖ | ‚ö†Ô∏è | ‚úÖ |\n",
        "| **Scanned PDFs** | ‚ùå | ‚ùå | ‚ùå | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |\n",
        "| **Multilingual** | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |\n",
        "| **Cost** | Free | Free | Free | Free | Free | Free | ~$0.075/1M tokens |\n",
        "| **Best For** | Digital text | Text + tables | Quick conversion | Scanned + tables | Fast + layout | Asian languages | Visual content |\n",
        "\n",
        "---\n",
        "\n",
        "## Recommended Workflow\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  Analyze PDFs               ‚îÇ\n",
        "‚îÇ  1. Is it scanned?          ‚îÇ\n",
        "‚îÇ  2. Are images critical?    ‚îÇ\n",
        "‚îÇ  3. Complex layout?         ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "           ‚îÇ\n",
        "           ‚ñº\n",
        "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "    ‚îÇ Digital + Simple?‚îÇ‚îÄ‚îÄ‚îÄYes‚îÄ‚îÄ‚ñ∫ PyMuPDF4LLM / PDFPlumber / MarkItDown\n",
        "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "           ‚îÇNo\n",
        "           ‚ñº\n",
        "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "    ‚îÇ Scanned / Tables only          ‚îÇ\n",
        "    ‚îÇ (no critical visual content)?  ‚îÇ‚îÄ‚îÄ‚îÄYes‚îÄ‚îÄ‚ñ∫ Docling / Marker / PaddleOCR\n",
        "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "           ‚îÇNo\n",
        "           ‚ñº\n",
        "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "    ‚îÇ Complex layouts, formulas,   ‚îÇ\n",
        "    ‚îÇ charts,  diagrams,           ‚îÇ\n",
        "    ‚îÇ or visual content            ‚îÇ\n",
        "    ‚îÇ requiring interpretation?    ‚îÇ‚îÄ‚îÄ‚îÄYes‚îÄ‚îÄ‚ñ∫ VLM (Gemini / Claude / Local)\n",
        "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Special Considerations for Scanned Documents\n",
        "\n",
        "**Important:** Scanned PDFs always require OCR, regardless of layout complexity. Even if a scanned PDF has a simple layout, it must be processed with Category 2 tools (Docling, Marker, PaddleOCR) because the text is not digitally selectable.\n",
        "\n",
        "**How to identify scanned PDFs:**\n",
        "1. Try to select text in the PDF viewer - if you can't, it's scanned\n",
        "2. Check file size - scanned PDFs are typically much larger\n",
        "3. Look for image artifacts or slightly rotated text\n",
        "\n",
        "**Recommended tools by scenario:**\n",
        "- **English scanned documents:** Docling or Marker\n",
        "- **Multilingual scanned documents:** PaddleOCR (supports 80+ languages)\n",
        "- **Low-quality scans:** VLM approach for best accuracy\n",
        "- **High-volume scanned documents:** Marker (fastest processing)\n",
        "\n",
        "---\n",
        "\n",
        "## Best Practices\n",
        "\n",
        "### 1. Always Test on Sample Documents\n",
        "Before processing your entire corpus, test 3-5 representative PDFs from each category to validate extraction quality.\n",
        "\n",
        "### 2. Implement Quality Checks"
      ],
      "metadata": {
        "id": "aX-7q4FSaXZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_markdown_quality(md_file: Path) -> dict:\n",
        "    \"\"\"Check markdown conversion quality\"\"\"\n",
        "    content = md_file.read_text()\n",
        "    words = content.split()\n",
        "\n",
        "    return {\n",
        "        \"word_count\": len(words),\n",
        "        \"has_headers\": \"#\" in content,\n",
        "        \"has_tables\": \"|\" in content,\n",
        "        \"has_formulas\": \"$\" in content,\n",
        "        \"avg_line_length\": len(content) / max(content.count(\"\\n\"), 1),\n",
        "        \"empty_ratio\": content.count(\"\\n\\n\") / max(content.count(\"\\n\"), 1)\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "quality_metrics = validate_markdown_quality(Path(\"output.md\"))\n",
        "print(f\"Quality metrics: {quality_metrics}\")"
      ],
      "metadata": {
        "id": "pCtHijHyae5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Cost Management for VLMs\n",
        "\n",
        "For large-scale conversion projects:\n",
        "- Start with Gemini 2.0 Flash (most cost-effective)\n",
        "- Use selective VLM processing: Category 1-2 tools for most pages, VLM only for critical visual pages\n",
        "- Implement caching to avoid reprocessing\n",
        "- Consider local VLMs for sensitive documents (deploy Qwen2-VL or LLaVA)\n",
        "\n",
        "### 4. Handling Mixed Document Types"
      ],
      "metadata": {
        "id": "npym5nYOagsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def smart_convert_pdf(pdf_path: str, api_key: str = None):\n",
        "    \"\"\"\n",
        "    Intelligently choose conversion method based on PDF characteristics.\n",
        "    \"\"\"\n",
        "    # Quick analysis\n",
        "    doc = fitz.open(pdf_path)\n",
        "    sample_page = doc[0]\n",
        "\n",
        "    # Check if text is selectable\n",
        "    text = sample_page.get_text()\n",
        "    is_scanned = len(text.strip()) < 50  # Likely scanned if very little text\n",
        "\n",
        "    # Check for images\n",
        "    image_count = len(sample_page.get_images())\n",
        "    has_images = image_count > 2\n",
        "\n",
        "    doc.close()\n",
        "\n",
        "    # Route to appropriate tool\n",
        "    if is_scanned:\n",
        "        print(\"‚Üí Using Docling (scanned document)\")\n",
        "        return convert_medium_pdfs_docling(pdf_path, \"output\")\n",
        "    elif has_images:\n",
        "        print(\"‚Üí Using VLM (image-heavy)\")\n",
        "        return convert_complex_pdfs_vlm(pdf_path, api_key)\n",
        "    else:\n",
        "        print(\"‚Üí Using PyMuPDF4LLM (simple digital PDF)\")\n",
        "        return convert_simple_pdfs_pymupdf4llm(pdf_path, \"output\")"
      ],
      "metadata": {
        "id": "WbhpvfZHajRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "Choosing the right PDF-to-Markdown converter directly impacts your RAG system's performance. Remember:\n",
        "\n",
        "- üìÑ **Simple digital PDFs** ‚Üí PyMuPDF4LLM, PDFPlumber, or MarkItDown\n",
        "- üìä **Scanned PDFs or tables** ‚Üí Docling, Marker, or PaddleOCR\n",
        "- üñºÔ∏è **Image-heavy complex PDFs** ‚Üí VLM (Gemini 2.0 Flash for cloud, Qwen3-VL for local)\n",
        "\n",
        "Start with the simplest tool that meets your needs. Upgrade to more sophisticated methods only when quality demands it. Your extraction strategy should match your document characteristics and project requirements.\n",
        "\n",
        "For production systems, consider implementing a hybrid approach that automatically routes PDFs to the appropriate conversion tool based on their characteristics. This maximizes both quality and cost-efficiency.\n",
        "\n",
        "Happy converting! üöÄ"
      ],
      "metadata": {
        "id": "1xvIRTadal54"
      }
    }
  ]
}